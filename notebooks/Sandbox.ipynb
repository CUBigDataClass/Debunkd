{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import configparser\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('credentials.ini')\n",
    "api_user = config['GNIP_API']['username']\n",
    "api_pass = config['GNIP_API']['password']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GNIP API search filters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GnipData():\n",
    "    \n",
    "    def __init__(maxResults, geolocation, fromDate, toDate):\n",
    "        self.maxResults = maxResults\n",
    "        self.geolocation = geolocation\n",
    "        self.fromDate = fromDate\n",
    "        self.toDate = toDate\n",
    "        self._cred = (api_user, api_pass)\n",
    "        self.url = \"https://gnip-api.twitter.com/search/\" \\\n",
    "        \"fullarchive/accounts/greg-students/prod.json\"\n",
    "    \n",
    "    \n",
    "    def fetchTweets(queries):\n",
    "        params = {'fromDate':'201401010000',\n",
    "                  'toDate': '201703200000',\n",
    "                  'maxResults':self.maxResults}\n",
    "        \n",
    "        for query in queries:\n",
    "            params['query'] = query\n",
    "            \n",
    "            response = requests.get(self.url,\n",
    "                                    params=params,\n",
    "                                    auth=self._cred)\n",
    "\n",
    "            queueKafka(response.json()['results'])\n",
    "            \n",
    "            while ('next' in response.json().keys()):\n",
    "                params['next'] = response.json()['next']\n",
    "                \n",
    "                response = requests.get(url,\n",
    "                                        params=params,\n",
    "                                        auth=self._cred)\n",
    "\n",
    "                queueKafka(response.json()['results'])\n",
    "\n",
    "    \n",
    "    def queueKafka(json_data):\n",
    "        # queue json data in kafka\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SparkProcessing():\n",
    "    \n",
    "    def __init__(snopes_urls):\n",
    "        self.urls = snopes_urls\n",
    "    \n",
    "    \n",
    "    def runSpark():\n",
    "        getQueries(self.urls)\n",
    "    \n",
    "    \n",
    "    def getQueries(urls):\n",
    "        # spark processing on urls to get keywords\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process_urls = SparkProcessing(snopes_urls)\n",
    "# queries = process_urls.runSpark()\n",
    "\n",
    "# search = GnipData(100, 'Boulder', blah, blah)\n",
    "# search.fetchTweets(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetchTweets(query, maxResults=500):\n",
    "    # search API url\n",
    "    url = \"https://gnip-api.twitter.com/search/\" \\\n",
    "    \"fullarchive/accounts/greg-students/prod.json\"\n",
    "    \n",
    "    # storing auth credentials in a hidden variable\n",
    "    _cred=(api_user, api_pass)\n",
    "    \n",
    "    # setting parameters to append to the url\n",
    "    params = {'query':query,\n",
    "              'fromDate':'201401010000',\n",
    "              'toDate': '201703200000',\n",
    "              'maxResults': 500}\n",
    "    \n",
    "    # making a GET request to the API\n",
    "    response = requests.get(url,\n",
    "                            params=params,\n",
    "                            auth=_cred)\n",
    "    \n",
    "    # storing the number of tweets returned\n",
    "    reslen = len(response.json()['results'])\n",
    "    \n",
    "    # checking if more tweets are available\n",
    "    while ('next' in response.json().keys()):\n",
    "\n",
    "        yield reslen\n",
    "        \n",
    "        params['next'] = response.json()['next']\n",
    "\n",
    "        response = requests.get(url,\n",
    "                                params=params,\n",
    "                                auth=_cred)\n",
    "\n",
    "        reslen += len(response.json()['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# using search API word locality filter\n",
    "for num_tweets in fetchTweets(\"obama thank you\"):\n",
    "    print(num_tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import configparser\n",
    "from pykafka import KafkaClient\n",
    "\n",
    "##parameters for the search\n",
    "url =\"https://gnip-api.twitter.com/search/fullarchive/accounts/greg-students/prod.json\"\n",
    "parameters = { 'query':'gnip', 'maxResults':'10',\n",
    "'fromDate':'201701010000', 'toDate':'201701050000'}\n",
    "\n",
    "##reading credentails file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('credentials.ini')\n",
    "\n",
    "##connecting to the kafka client\n",
    "client = KafkaClient(\"localhost:9092\")\n",
    "\n",
    "##selcting the topic\n",
    "topic = client.topics[a]\n",
    "\n",
    "response = requests.get(url,\n",
    "                        auth=(config['GNIP_API']['username'],config['GNIP_API']['password']),\n",
    "                        params=parameters)\n",
    "\n",
    "res = response.json()['results']\n",
    "consumer = topic.get_simple_consumer()\n",
    "##writing into topic\n",
    "with topic.get_producer() as producer:\n",
    "    for r in res:\n",
    "        producer.produce(bytes(json.dumps(r).encode(\"utf-8\")))\n",
    "        msg = consumer.consume()\n",
    "        print(msg.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
